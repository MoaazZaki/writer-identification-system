{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tester.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "L35OEK3O5N0y",
        "w2R2AVfh5ALl",
        "JbnJpA-R5Kj2",
        "aM2lV49IS4Zw",
        "lGIOsTvYoEd8"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h113kF2YVVnL"
      },
      "source": [
        "**This notebook is for testing purposes only, refer to *Trainer.ipynb* to see the full code with visualization, model testing and previous trials.**\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L35OEK3O5N0y"
      },
      "source": [
        "# Essentials"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a1BqXDkqABQ",
        "outputId": "08cfe31a-9b21-41c1-eaa9-7fd4cad70ff4"
      },
      "source": [
        "from google.colab import drive # Don't run this cell if you're not using colab\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYaFZ8W2DyJq"
      },
      "source": [
        "#All needed imports\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from itertools import product\r\n",
        "from skimage.filters import sobel\r\n",
        "from skimage import feature\r\n",
        "import pathlib\r\n",
        "#models\r\n",
        "from sklearn.svm import SVC\r\n",
        "#testing\r\n",
        "import os\r\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHX09g--XOzo"
      },
      "source": [
        "**Note: Change PATH_TO_TEST_FOLDER and PATH_TO_TEST_DATA as described below**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAKb1lRSndPe"
      },
      "source": [
        "#constants\r\n",
        "MASK_CC_THRESHOLD=100\r\n",
        "LINES_PEAKS_DIVIDER=3\r\n",
        "#paths\r\n",
        "PATH_TO_TEST_FOLDER = \"/content/drive/MyDrive/Pattern Project/Test Set\" # Path to folder that will have results.txt, time.txt and data folder\r\n",
        "PATH_TO_TEST_DATA = PATH_TO_TEST_FOLDER + \"/data\" # Data folder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2R2AVfh5ALl"
      },
      "source": [
        "# Preproccessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC6zGX1J5D90"
      },
      "source": [
        "def preProcessTheImage(image):\r\n",
        "    image = cv2.GaussianBlur(image, (5, 5), 0)[:, 150:-50] # Blur the image and crop some white space from both sides to fasten the process \r\n",
        "    thresh, bin_img = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU) #get the binary image\r\n",
        "    contours, _ = cv2.findContours(bin_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE) #get the contours of the binary image\r\n",
        "    height, width = image.shape\r\n",
        "    top, bottom, left, right = 0, height - 1, 0, width - 1\r\n",
        "    \r\n",
        "    countoursBoundingBox = np.asarray([np.asarray(cv2.boundingRect(contour)) for contour in contours])\r\n",
        "    countoursBoundingBox = countoursBoundingBox[countoursBoundingBox[:,2] > 1000]\r\n",
        "    cutMask = countoursBoundingBox[:,1] < height // 2\r\n",
        "    upperHalfCountours = countoursBoundingBox[cutMask]\r\n",
        "    lowerHalfCountours = countoursBoundingBox[np.logical_not(cutMask)]\r\n",
        "    top = np.max(upperHalfCountours[:,1]+upperHalfCountours[:,3]+10)\r\n",
        "    bottom = np.min(lowerHalfCountours[:,1]-10)\r\n",
        "\r\n",
        "    noiselessImage = cv2.erode(bin_img, np.ones((3, 3), np.uint8), iterations=2) #erode the image to get rid of any noise\r\n",
        "    horizontalHistogram = np.sum(noiselessImage, axis=1)[top:bottom+1] \r\n",
        "    verticalHistogram = np.sum(noiselessImage, axis=0) \r\n",
        "    left+=(verticalHistogram!=0).argmax()\r\n",
        "    right-=(verticalHistogram[::-1]!=0).argmax()\r\n",
        "    top+=(horizontalHistogram!=0).argmax()\r\n",
        "    bottom-=(horizontalHistogram[::-1]!=0).argmax()\r\n",
        "    return image[top:bottom + 1, left:right + 1],bin_img[top:bottom + 1, left:right + 1] #preprocessed image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbnJpA-R5Kj2"
      },
      "source": [
        "# Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSepblylpMbN"
      },
      "source": [
        "def getConnectedComponents(binaryImage): #only returns the centroids, stats, and the visual image of the needed components \r\n",
        "#--------------------------------------------------------------------------------------------------------------------------#\r\n",
        "#cv2.CC_STAT_LEFT The leftmost (x) coordinate which is the inclusive start of the bounding box in the horizontal direction.\r\n",
        "#cv2.CC_STAT_TOP The topmost (y) coordinate which is the inclusive start of the bounding box in the vertical direction.\r\n",
        "#cv2.CC_STAT_WIDTH The horizontal size of the bounding box\r\n",
        "#cv2.CC_STAT_HEIGHT The vertical size of the bounding box\r\n",
        "#cv2.CC_STAT_AREA The total area (in pixels) of the connected component\r\n",
        "#--------------------------------------------------------------------------------------------------------------------------#\r\n",
        "  nb_components, cc_output, stats, centroids  = cv2.connectedComponentsWithStats(binaryImage, connectivity=8)\r\n",
        "  mask = np.where(stats[:,-1] > MASK_CC_THRESHOLD)[0] #get rid of all the commas and periods. The MASK_CC_THRESHOLD value could be change later on.\r\n",
        "  return centroids[mask],stats[mask],cc_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcHHBnY0snxT"
      },
      "source": [
        "# Get the horzinotal projection of sobel image\r\n",
        "def getHorizontalHist(binaryImage):\r\n",
        "  sobelImg = sobel(binaryImage)\r\n",
        "  return np.sum(sobelImg,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPDnH9gNsoG4"
      },
      "source": [
        "#Take the top peaks\r\n",
        "def getLinesPeaks(horizontalHist,binaryImage):\r\n",
        "  threshold = (np.max(horizontalHist) - np.min(horizontalHist)) / LINES_PEAKS_DIVIDER\r\n",
        "  peaks_index = np.where(horizontalHist > threshold)[0]\r\n",
        "  linesImage = binaryImage.copy()\r\n",
        "  linesImage[peaks_index,:] = 0\r\n",
        "  return peaks_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2yHLkOnsxPS"
      },
      "source": [
        "def consecutive(data, stepsize=1):\r\n",
        "    return np.split(data, np.where(np.diff(data) != stepsize)[0]+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQFwTXQ7sxwY"
      },
      "source": [
        "def getLinesBoundaries(binaryImage): #to know the limits of each line\r\n",
        "  horizontalHist=getHorizontalHist(binaryImage) \r\n",
        "  peaks_index=getLinesPeaks(horizontalHist,binaryImage)\r\n",
        "  hpClusters = consecutive(peaks_index)\r\n",
        "\r\n",
        "  threshold = -1\r\n",
        "  for i in range(len(hpClusters)):\r\n",
        "    value = len(hpClusters[i])\r\n",
        "    if threshold < value:\r\n",
        "      threshold = value\r\n",
        "\r\n",
        "  threshold /= 2\r\n",
        "  minArray = []\r\n",
        "  maxArray = []\r\n",
        "\r\n",
        "  for i in range(len(hpClusters)):\r\n",
        "    if len(hpClusters[i]) >= threshold:\r\n",
        "      minArray.append(hpClusters[i][0])\r\n",
        "      maxArray.append(hpClusters[i][-1])\r\n",
        "\r\n",
        "  lines=[0]\r\n",
        "  avg = 0\r\n",
        "  for i in range(len(maxArray)-1):\r\n",
        "    diff = (minArray[i+1] - maxArray[i])/2\r\n",
        "    lines.append( int(maxArray[i] + diff))\r\n",
        "    avg += diff\r\n",
        "\r\n",
        "  if len(maxArray) > 1:\r\n",
        "    lines.append(int(maxArray[-1] + avg/(len(maxArray)-1)))\r\n",
        "  else:\r\n",
        "    lines.append(int(maxArray[-1] + avg))\r\n",
        "\r\n",
        "  return lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsTi3AMUsx_i"
      },
      "source": [
        "def createTextureImage(greyImage,binaryImage): #coverts the text image to texture\r\n",
        "  lines=getLinesBoundaries(binaryImage) #get the seperating lines\r\n",
        "\r\n",
        "  centroids,stats,cc_output =getConnectedComponents(binaryImage) #get the connected components\r\n",
        "  textureImage = np.full(binaryImage.shape,255)\r\n",
        "  y_current = 0\r\n",
        "  currentRange = 0\r\n",
        "  y_avg = 0\r\n",
        "  y_sum = 0\r\n",
        "  y_count = 0\r\n",
        "\r\n",
        "  y_sum_prev=0\r\n",
        "  y_count_prev = 0\r\n",
        "  y_prev = 0\r\n",
        "  \r\n",
        "  x_start = stats[1,0]\r\n",
        "  x_end = 0\r\n",
        "  for i in range(1,len(centroids)):\r\n",
        "    \r\n",
        "    if currentRange+1 == len(lines):\r\n",
        "      break\r\n",
        "    if lines[currentRange+1] > centroids[i,1] :\r\n",
        "      if not (lines[currentRange] < centroids[i,1]):\r\n",
        "          currentRange -= 1\r\n",
        "          y_avg = y_sum_prev / y_count_prev\r\n",
        "          y_sum = y_sum_prev\r\n",
        "          y_count = y_count_prev\r\n",
        "    else:\r\n",
        "      y_avg = y_sum / y_count\r\n",
        "      y_avg_prev = y_avg\r\n",
        "      y_prev = y_current\r\n",
        "      y_current += int(y_avg/2)\r\n",
        "      currentRange += 1\r\n",
        "      y_sum_prev=y_sum\r\n",
        "      y_count_prev = y_count\r\n",
        "      y_sum =0\r\n",
        "      y_count =0\r\n",
        "\r\n",
        "      \r\n",
        "    if stats[i,0]< x_start:\r\n",
        "        x_start = stats[i,0]\r\n",
        "    if stats[i-1,0] > x_end:\r\n",
        "      x_end = stats[i-1,0] + stats[i-1,2]  \r\n",
        "  \r\n",
        "\r\n",
        "    toBeCopied = greyImage[stats[i,1]: stats[i,1] + stats[i,3],stats[i,0] :stats[i,0] + stats[i,2]]\r\n",
        "    toBeCopiedMask = toBeCopied <= 200\r\n",
        "    textureImage[y_current:y_current+ stats[i,3],stats[i,0] :stats[i,0] + stats[i,2]][toBeCopiedMask] = toBeCopied[toBeCopiedMask]\r\n",
        "    y_sum += stats[i,3]\r\n",
        "    y_count += 1\r\n",
        "\r\n",
        "  return textureImage[:int(y_current+y_avg*1.5),int(x_start):int(x_end)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc8ezyYqwtKR"
      },
      "source": [
        "def divideTextureImageIntoBlocks(textureImage,divide=3): #takes in a numpy textue mage\r\n",
        "    h, w = textureImage.shape\r\n",
        "    h_new= h - (h % divide)\r\n",
        "    w_new= w - (w % divide) \r\n",
        "    textureImage=textureImage[0:h_new, 0:w_new]\r\n",
        "    segment1=h_new//divide\r\n",
        "    segment2=w_new//divide\r\n",
        "    return (textureImage.reshape(h_new//segment1, segment1, -1, segment2)\r\n",
        "               .swapaxes(1,2)\r\n",
        "               .reshape(-1, segment1, segment2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIJkNl6KKUAY"
      },
      "source": [
        "def convertImagesIntoTextureBlocks(dataset,authorMap,exp_beta=30):\r\n",
        "  textureBlocks=[]\r\n",
        "  currentPath = ''\r\n",
        "  labels = []\r\n",
        "  for path,author in dataset.values:\r\n",
        "    \r\n",
        "    if path[0] <= 'd':\r\n",
        "      currentPath = PATH_TO_A_D\r\n",
        "    elif path[0] <= 'h':\r\n",
        "      currentPath = PATH_TO_E_H\r\n",
        "    else:\r\n",
        "      currentPath = PATH_TO_I_Z\r\n",
        "    greyImage = cv2.imread(currentPath+path,cv2.IMREAD_GRAYSCALE)\r\n",
        "\r\n",
        "    gImg,bImg = preProcessTheImage(greyImage)\r\n",
        "\r\n",
        "\r\n",
        "    labels+=list(np.repeat(author, 9))\r\n",
        "    textureBlocks += list(divideTextureImageIntoBlocks(createTextureImage(gImg,bImg)))\r\n",
        "    if np.random.exponential(authorMap[author]/exp_beta) <= 0.5:\r\n",
        "      seq = iaa.Sequential([\r\n",
        "       iaa.Crop(px=(np.min(gImg.shape)//5, np.min(gImg.shape)//3)), \r\n",
        "      ])\r\n",
        "      \r\n",
        "      random_gImg = seq(images=gImg)\r\n",
        "      if random_gImg.shape[0] < 600:\r\n",
        "        continue\r\n",
        "      thresh, random_bImg = cv2.threshold(random_gImg, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU) #get the binary image\r\n",
        "      textureBlocks += list(divideTextureImageIntoBlocks(createTextureImage(random_gImg,random_bImg)))\r\n",
        "      labels+=list(np.repeat(author, 9))\r\n",
        "      authorMap[author] +=1\r\n",
        "  return textureBlocks,labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM2lV49IS4Zw"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI8tyPw1MmpF"
      },
      "source": [
        "def getFeaturesLBP(textureBlock, sampling_pixels=8,radius=3):\r\n",
        "    # normalize the values of the grey scale image\r\n",
        "    i_min = np.min(textureBlock)\r\n",
        "    i_max = np.max(textureBlock)\r\n",
        "    if (i_max - i_min != 0):\r\n",
        "        textureBlock = (textureBlock - i_min)/(i_max-i_min)\r\n",
        "    \r\n",
        "    # compute LBP\r\n",
        "    lbp = feature.local_binary_pattern(textureBlock, sampling_pixels, radius)\r\n",
        "    \r\n",
        "    # compute the histogram of the matrix obtained from LBP to get 256 features\r\n",
        "    (hist, _) = np.histogram(lbp.ravel(),bins=256)\r\n",
        "\r\n",
        "    # normalization might or might not be required, if it is uncomment these two lines\r\n",
        "    hist = hist.astype(np.float)\r\n",
        "    #hist /= np.sum(hist)\r\n",
        "    return hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y0IK7YDVVO1"
      },
      "source": [
        "def featuresOfMultipleTextureBlocksLBP(textureBlocks,radius=3): #takes in a python list of texture blocks\r\n",
        "  features=[]\r\n",
        "  for i in range(len(textureBlocks)):\r\n",
        "    features.append(getFeaturesLBP(textureBlocks[i],radius=radius))\r\n",
        "  return np.asarray(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGIOsTvYoEd8"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJhkIP8SPyT7"
      },
      "source": [
        "def wholePipeline(imagePath,author,radius=3,divide=3):\r\n",
        "  return featuresOfMultipleTextureBlocksLBP(\r\n",
        "      divideTextureImageIntoBlocks(\r\n",
        "          createTextureImage(\r\n",
        "              *preProcessTheImage(cv2.imread(str(imagePath),cv2.IMREAD_GRAYSCALE))),divide=divide),\r\n",
        "              radius=radius),np.repeat(author,divide*divide) #returns features(9,256) and labels 9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPTSh2SoCVqF"
      },
      "source": [
        "def wholePipelineForTest(imagePath,radius=3,divide=3):\r\n",
        "  return featuresOfMultipleTextureBlocksLBP(\r\n",
        "      divideTextureImageIntoBlocks(\r\n",
        "          createTextureImage(\r\n",
        "              *preProcessTheImage(cv2.imread(str(imagePath),cv2.IMREAD_GRAYSCALE))),divide=divide),\r\n",
        "              radius=radius) #returns features(9,256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u85M64it62oh"
      },
      "source": [
        "def testTheModel(train,train_labels,test,radius=3,divide=3,C=5.0):\r\n",
        "  classifier = SVC(C=C, gamma='auto', probability=True)\r\n",
        "  numberOfBlocks=divide*divide\r\n",
        "  allFeatures = np.zeros((numberOfBlocks*6,256),dtype=float)\r\n",
        "  allLabels = np.zeros(numberOfBlocks*6,dtype=int)\r\n",
        "\r\n",
        "  for i in range(len(train)):\r\n",
        "    features,labels=wholePipeline(train[i],train_labels[i],radius=radius,divide=divide)\r\n",
        "    allFeatures[i*numberOfBlocks:i*numberOfBlocks+numberOfBlocks,:]=features\r\n",
        "    allLabels[i*numberOfBlocks:i*numberOfBlocks+numberOfBlocks]=labels\r\n",
        "  \r\n",
        "  maxColWise=np.max(allFeatures,axis=0)\r\n",
        "  allFeatures/=maxColWise #normalize the features column wise by dividing by the max of each col\r\n",
        "  classifier.fit(allFeatures, allLabels)\r\n",
        "  \r\n",
        "  testFeatures = wholePipelineForTest(test,radius=radius,divide=divide)\r\n",
        "  testFeatures/=maxColWise\r\n",
        "  prediction= np.bincount(classifier.predict(testFeatures)).argmax()\r\n",
        "\r\n",
        "  return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2bQKVgSpR5y"
      },
      "source": [
        "# Reading Data and Writing to files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFmjyP9fpzT3"
      },
      "source": [
        "trainImages = []\r\n",
        "labels = []\r\n",
        "testImages = []\r\n",
        "\r\n",
        "test_cases = os.listdir(PATH_TO_TEST_DATA)\r\n",
        "test_cases.sort()\r\n",
        "for sample in test_cases: #Sample folder level\r\n",
        "    for author in pathlib.Path(PATH_TO_TEST_DATA+'/'+sample).iterdir(): #Author in sample folder level\r\n",
        "      if author.is_file():\r\n",
        "        testImages.append(str(author))\r\n",
        "      else:\r\n",
        "        for image in pathlib.Path(author).iterdir(): #Image for author in sample folder level\r\n",
        "          labels.append(int(str(author)[-1]))\r\n",
        "          if not author.is_file():\r\n",
        "            trainImages.append(str(image))\r\n",
        "\r\n",
        "\r\n",
        "results = open(PATH_TO_TEST_FOLDER+'/'+\"results.txt\",\"w\")\r\n",
        "time_file = open(PATH_TO_TEST_FOLDER+'/'+\"time.txt\",\"w\")\r\n",
        "counter = 0\r\n",
        "for i in range(0,len(trainImages),6):\r\n",
        "  start = time.perf_counter() #start time\r\n",
        "  answer = testTheModel(trainImages[i:i+6],labels[i:i+6],testImages[counter],C=8.0) #Pipeline of the 7 images\r\n",
        "  end = time.perf_counter() #end time\r\n",
        "\r\n",
        "  results.write(str(answer)+'\\n') #Writing results\r\n",
        "  time_file.write(str(np.round(end-start,2))+'\\n') #Writing results\r\n",
        "  counter+= 1\r\n",
        "\r\n",
        "results.close()\r\n",
        "time_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IJcROisjVxR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}